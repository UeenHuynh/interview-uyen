# ğŸŒ Curse of Dimensionality - Lá»i Nguyá»n Äa Chiá»u

## ğŸ“‹ Tá»•ng Quan

Code nÃ y minh há»a má»™t trong nhá»¯ng hiá»‡n tÆ°á»£ng pháº£n trá»±c quan nháº¥t trong khÃ´ng gian nhiá»u chiá»u: **Curse of Dimensionality** (Lá»i Nguyá»n Äa Chiá»u). Khi sá»‘ chiá»u tÄƒng lÃªn, táº¥t cáº£ cÃ¡c Ä‘iá»ƒm trá»Ÿ nÃªn "xa nhau nhÆ° nhau" - má»™t khÃ¡i niá»‡m quan trá»ng trong Machine Learning, Data Science vÃ  High-Dimensional Statistics.

## ğŸ¯ Hiá»‡n TÆ°á»£ng ChÃ­nh

### Quan SÃ¡t Thá»±c Nghiá»‡m
- **KhÃ´ng gian 3D**: Khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm phÃ¢n bá»‘ rá»™ng (tá»« ~0 Ä‘áº¿n ~2)
- **KhÃ´ng gian 100D**: Táº¥t cáº£ khoáº£ng cÃ¡ch táº­p trung xung quanh âˆš2 â‰ˆ 1.414

### Ã NghÄ©a
Trong khÃ´ng gian nhiá»u chiá»u:
- KhÃ¡i niá»‡m "gáº§n" vÃ  "xa" máº¥t Ä‘i Ã½ nghÄ©a
- Má»i Ä‘iá»ƒm Ä‘á»u cÃ¡ch Ä‘á»u nhau
- CÃ¡c thuáº­t toÃ¡n dá»±a trÃªn khoáº£ng cÃ¡ch (KNN, K-Means) trá»Ÿ nÃªn kÃ©m hiá»‡u quáº£

---

## ğŸ“ Giáº£i ThÃ­ch ToÃ¡n Há»c Chi Tiáº¿t

### 1ï¸âƒ£ Äá»‹nh NghÄ©a CÆ¡ Báº£n

**Máº·t cáº§u Ä‘Æ¡n vá»‹ trong n chiá»u:**
```
S^(n-1) = {x âˆˆ â„â¿ : ||x|| = 1}
```
NghÄ©a lÃ : táº¥t cáº£ Ä‘iá»ƒm x cÃ³ khoáº£ng cÃ¡ch Ä‘áº¿n gá»‘c tá»a Ä‘á»™ = 1

**Khoáº£ng cÃ¡ch Euclidean:**
```
d(x,y) = ||x - y|| = âˆš(âˆ‘áµ¢â‚Œâ‚â¿ (xáµ¢ - yáµ¢)Â²)
```

---

### 2ï¸âƒ£ Chá»©ng Minh ToÃ¡n Há»c

#### BÆ°á»›c 1: Khai triá»ƒn khoáº£ng cÃ¡ch bÃ¬nh phÆ°Æ¡ng

Vá»›i hai Ä‘iá»ƒm **x**, **y** trÃªn máº·t cáº§u Ä‘Æ¡n vá»‹:

```
dÂ²(x,y) = ||x - y||Â²
        = (x - y)áµ€(x - y)
        = xáµ€x - 2xáµ€y + yáµ€y
        = ||x||Â² - 2âŸ¨x,yâŸ© + ||y||Â²
```

VÃ¬ x, y náº±m trÃªn máº·t cáº§u Ä‘Æ¡n vá»‹ nÃªn ||x|| = ||y|| = 1:

```
dÂ²(x,y) = 1 - 2âŸ¨x,yâŸ© + 1 = 2(1 - âŸ¨x,yâŸ©)
```

Trong Ä‘Ã³ âŸ¨x,yâŸ© lÃ  **tÃ­ch vÃ´ hÆ°á»›ng (dot product)**.

---

#### BÆ°á»›c 2: TÃ­ch vÃ´ hÆ°á»›ng trong khÃ´ng gian nhiá»u chiá»u

TÃ­ch vÃ´ hÆ°á»›ng cá»§a hai vector ngáº«u nhiÃªn trÃªn máº·t cáº§u:

```
âŸ¨x,yâŸ© = âˆ‘áµ¢â‚Œâ‚â¿ xáµ¢yáµ¢
```

**TÃ­nh cháº¥t quan trá»ng:**
- Má»—i thÃ nh pháº§n xáµ¢yáµ¢ lÃ  biáº¿n ngáº«u nhiÃªn Ä‘á»™c láº­p
- E[xáµ¢yáµ¢] = E[xáµ¢]E[yáµ¢] = 0 (vÃ¬ phÃ¢n bá»‘ Ä‘á»‘i xá»©ng)
- Var(xáµ¢yáµ¢) â‰ˆ 1/n (do rÃ ng buá»™c ||x|| = 1)

---

#### BÆ°á»›c 3: Ãp dá»¥ng Äá»‹nh LÃ½ Giá»›i Háº¡n Trung TÃ¢m (CLT)

TÃ­ch vÃ´ hÆ°á»›ng lÃ  **tá»•ng cá»§a n biáº¿n ngáº«u nhiÃªn Ä‘á»™c láº­p**:

```
âŸ¨x,yâŸ© = âˆ‘áµ¢â‚Œâ‚â¿ xáµ¢yáµ¢
```

Theo **Central Limit Theorem**:
- Khi n â†’ âˆ: âŸ¨x,yâŸ© ~ N(0, ÏƒÂ²/n)
- PhÆ°Æ¡ng sai giáº£m theo 1/n
- **âŸ¨x,yâŸ© â†’ 0** khi n â†’ âˆ

**Ã nghÄ©a hÃ¬nh há»c**: Hai vector ngáº«u nhiÃªn trong khÃ´ng gian nhiá»u chiá»u gáº§n nhÆ° **trá»±c giao** (vuÃ´ng gÃ³c) vá»›i nhau!

---

#### BÆ°á»›c 4: Káº¿t luáº­n

Khi n â†’ âˆ:

```
âŸ¨x,yâŸ© â†’ 0

âŸ¹ dÂ²(x,y) = 2(1 - âŸ¨x,yâŸ©) â†’ 2(1 - 0) = 2

âŸ¹ d(x,y) â†’ âˆš2 â‰ˆ 1.414
```

**Káº¿t quáº£**: Má»i cáº·p Ä‘iá»ƒm ngáº«u nhiÃªn trÃªn máº·t cáº§u Ä‘Æ¡n vá»‹ trong khÃ´ng gian nhiá»u chiá»u Ä‘á»u cÃ³ khoáº£ng cÃ¡ch xáº¥p xá»‰ âˆš2!

---

### 3ï¸âƒ£ Äá»™ Táº­p Trung (Concentration of Measure)

**Coefficient of Variation (CV)**:
```
CV = Ïƒ/Î¼ = std(distances)/mean(distances)
```

- **3D**: CV â‰ˆ 0.25 (phÃ¢n tÃ¡n cao)
- **100D**: CV â‰ˆ 0.03 (cá»±c ká»³ táº­p trung)

Khi sá»‘ chiá»u tÄƒng, CV â†’ 0, nghÄ©a lÃ  phÃ¢n phá»‘i khoáº£ng cÃ¡ch trá»Ÿ thÃ nh má»™t "Ä‘Æ°á»ng nhá»n" xung quanh âˆš2.

---

## ğŸ”¬ Chi Tiáº¿t Code

### HÃ m `generate_sphere_points(n_points, dim)`

**Thuáº­t toÃ¡n**: Normalization Method

```python
# BÆ°á»›c 1: Táº¡o Ä‘iá»ƒm tá»« phÃ¢n phá»‘i chuáº©n
points = np.random.randn(n_points, dim)  # N(0,1)

# BÆ°á»›c 2: Chuáº©n hÃ³a vá» máº·t cáº§u Ä‘Æ¡n vá»‹
points_normalized = points / ||points||
```

**Táº¡i sao phÆ°Æ¡ng phÃ¡p nÃ y hoáº¡t Ä‘á»™ng?**

Äá»‹nh lÃ½: Náº¿u **X** ~ N(0, I_n) (phÃ¢n phá»‘i chuáº©n Ä‘a biáº¿n), thÃ¬ **X/||X||** phÃ¢n bá»‘ Ä‘á»u trÃªn máº·t cáº§u Ä‘Æ¡n vá»‹ S^(n-1).

**Chá»©ng minh trá»±c quan:**
- PhÃ¢n phá»‘i chuáº©n cÃ³ tÃ­nh Ä‘á»‘i xá»©ng cáº§u
- Má»i hÆ°á»›ng Ä‘á»u cÃ³ xÃ¡c suáº¥t nhÆ° nhau
- Chuáº©n hÃ³a chá»‰ chiáº¿u Ä‘iá»ƒm lÃªn máº·t cáº§u mÃ  khÃ´ng lÃ m máº¥t tÃ­nh Ä‘á»“ng nháº¥t

---

### HÃ m `compute_pairwise_distances(points)`

TÃ­nh táº¥t cáº£ C(n,2) = n(n-1)/2 khoáº£ng cÃ¡ch giá»¯a cÃ¡c cáº·p Ä‘iá»ƒm.

Vá»›i 1000 Ä‘iá»ƒm:
```
Sá»‘ cáº·p = 1000 Ã— 999 / 2 = 499,500 khoáº£ng cÃ¡ch
```

---

### HÃ m `plot_distance_histograms()`

Trá»±c quan hÃ³a sá»± khÃ¡c biá»‡t giá»¯a:
- **3D**: Histogram rá»™ng, nhiá»u giÃ¡ trá»‹ khÃ¡c nhau
- **100D**: Histogram háº¹p, táº­p trung xung quanh âˆš2

---

## ğŸ’¡ Ã NghÄ©a Thá»±c Tiá»…n

### 1. Machine Learning
- **K-Nearest Neighbors (KNN)**: Trong khÃ´ng gian nhiá»u chiá»u, "k lÃ¡ng giá»ng gáº§n nháº¥t" khÃ´ng cÃ²n Ã½ nghÄ©a vÃ¬ má»i Ä‘iá»ƒm Ä‘á»u xa nhÆ° nhau
- **K-Means Clustering**: KhÃ³ phÃ¢n biá»‡t cÃ¡c cluster khi má»i Ä‘iá»ƒm cÃ¡ch Ä‘á»u nhau
- **Distance-based metrics**: Cáº§n giáº£m chiá»u (PCA, t-SNE) trÆ°á»›c khi Ã¡p dá»¥ng

### 2. Feature Engineering
- KhÃ´ng nÃªn sá»­ dá»¥ng quÃ¡ nhiá»u features khÃ´ng cáº§n thiáº¿t
- Dimensionality reduction lÃ  bÆ°á»›c quan trá»ng
- Feature selection > Feature addition

### 3. Data Visualization
- KhÃ´ng gian 2D/3D khÃ´ng pháº£n Ã¡nh Ä‘Ãºng cáº¥u trÃºc dá»¯ liá»‡u nhiá»u chiá»u
- Cáº§n phÆ°Æ¡ng phÃ¡p embedding cáº©n tháº­n (t-SNE, UMAP)

---

## ğŸš€ CÃ¡ch Cháº¡y Code

```bash
# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install numpy matplotlib scipy

# Cháº¡y script
python curse_of_dimensionality.py
```

**Output:**
1. Statistics cho khÃ´ng gian 3D vÃ  100D
2. Histogram so sÃ¡nh phÃ¢n phá»‘i khoáº£ng cÃ¡ch
3. File áº£nh: `curse_of_dimensionality.png`

---

## ğŸ“Š Káº¿t Quáº£ Máº«u

```
Statistics for 3D Sphere:
Mean distance:         1.411927
Std deviation:         0.351468
Coefficient of Var:    0.248949

Statistics for 100D Sphere:
Mean distance:         1.413769
Std deviation:         0.044127
Coefficient of Var:    0.031213

Theoretical limit: âˆš2 â‰ˆ 1.414214
100D mean:             1.413769
Difference:            0.000445
```

**Quan sÃ¡t**: Vá»›i chá»‰ 100 chiá»u, khoáº£ng cÃ¡ch Ä‘Ã£ há»™i tá»¥ ráº¥t gáº§n âˆš2!

---

## ğŸ§  Má»Ÿ Rá»™ng

### ThÃ­ Nghiá»‡m ThÃªm

1. **Thay Ä‘á»•i sá»‘ chiá»u**: Thá»­ vá»›i 5D, 10D, 50D, 200D Ä‘á»ƒ tháº¥y sá»± há»™i tá»¥
2. **Thay Ä‘á»•i sá»‘ Ä‘iá»ƒm**: Xem áº£nh hÆ°á»Ÿng cá»§a sample size
3. **Metric khÃ¡c**: Thá»­ Manhattan distance, Cosine similarity
4. **KhÃ´ng gian khÃ¡c**: Thá»­ vá»›i hypercube thay vÃ¬ sphere

### CÃ¢u Há»i Suy Ngáº«m

1. Táº¡i sao KNN váº«n hoáº¡t Ä‘á»™ng tá»‘t trong nhiá»u bÃ i toÃ¡n thá»±c táº¿ dÃ¹ cÃ³ nhiá»u chiá»u?
   - **Tráº£ lá»i**: Dá»¯ liá»‡u thá»±c táº¿ thÆ°á»ng náº±m trÃªn **manifold chiá»u tháº¥p** trong khÃ´ng gian nhiá»u chiá»u

2. LÃ m tháº¿ nÃ o Ä‘á»ƒ "chá»‘ng" láº¡i curse of dimensionality?
   - Dimensionality reduction (PCA, LDA, Autoencoders)
   - Feature selection
   - Regularization
   - Domain knowledge Ä‘á»ƒ chá»n features quan trá»ng

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

1. **"The Curse of Dimensionality"** - Richard Bellman (1961)
2. **"High-Dimensional Probability"** - Roman Vershynin
3. **"Pattern Recognition and Machine Learning"** - Christopher Bishop (Chapter 1.4)
4. **"The Elements of Statistical Learning"** - Hastie, Tibshirani, Friedman

---

## âš ï¸ LÆ°u Ã

- Code nÃ y mÃ´ phá»ng vá»›i sá»‘ Ä‘iá»ƒm há»¯u háº¡n, káº¿t quáº£ xáº¥p xá»‰ lÃ½ thuyáº¿t
- Vá»›i sá»‘ chiá»u cÃ ng cao, cáº§n cÃ ng nhiá»u Ä‘iá»ƒm Ä‘á»ƒ mÃ´ phá»ng chÃ­nh xÃ¡c
- Trong thá»±c táº¿, curse of dimensionality áº£nh hÆ°á»Ÿng tá»« ~10-20 chiá»u trá»Ÿ lÃªn

---

## ğŸ‘¨â€ğŸ’» TÃ¡c Giáº£ & License

Code minh há»a cho má»¥c Ä‘Ã­ch giÃ¡o dá»¥c vá» Curse of Dimensionality.

**LiÃªn há»‡**: Náº¿u cÃ³ cÃ¢u há»i vá» toÃ¡n há»c hoáº·c triá»ƒn khai, hÃ£y má»Ÿ issue!

---

## ğŸ“ Káº¿t Luáº­n

> "Trong khÃ´ng gian nhiá»u chiá»u, trá»±c giÃ¡c cá»§a chÃºng ta vá» hÃ¬nh há»c bá»‹ phÃ¡ vá»¡. Nhá»¯ng gÃ¬ Ä‘Ãºng trong 2D/3D khÃ´ng cÃ²n Ä‘Ãºng trong 100D."

Curse of Dimensionality khÃ´ng pháº£i lÃ  má»™t "bug" cá»§a toÃ¡n há»c, mÃ  lÃ  má»™t **Ä‘áº·c tÃ­nh cÆ¡ báº£n** cá»§a khÃ´ng gian nhiá»u chiá»u. Hiá»ƒu rÃµ nÃ³ giÃºp chÃºng ta thiáº¿t káº¿ cÃ¡c thuáº­t toÃ¡n Machine Learning hiá»‡u quáº£ hÆ¡n!

---

**ğŸŒŸ Happy Learning! ğŸŒŸ**